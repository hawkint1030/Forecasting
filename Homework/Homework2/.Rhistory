abline(h=mean(data$goldreturn,na.rm=TRUE),lty=2)
#Calculate return multipliers for real rate and breakeven
data$realrater <- 1 + (data$realrate / 100)
data$breakevenr <- 1 + (data$breakeven / 100)
#estimate bond fv, as described in website in notes
data$bondestimate <- (data$breakevenr^20)/(data$realrater^20)
#________________________________________________________________________________________#
#Estimate a Model
model <- lm(goldreturn ~ index + realrate, data = data)
modelsum <- summary(model)$coef
# data$returnestimate <- modelsum["(Intercept)","Estimate"] +
#                             modelsum["index","Estimate"] * data$index +
#                             modelsum["realrate","Estimate"] * data$realrate
# Try this instead (Above not entirely correct because you need to drop the first obs in
# each before doing the multiplication:
data$returnestimate <- c(NA,fitted(model))
#Graph Predicted Versus Actual
# Why not plot actual (dots) and predicted (line)
ggplot(data = data, aes(x = returnestimate, y = goldreturn))+ geom_point()
ggplot(data,aes(y=goldreturn,x=date)) +  geom_point()+ stat_smooth(method = "lm",se=FALSE)
#___________________________________________________________________________________________#
#New Model with lag
model <- lm(goldreturn ~ index + realrate + lag(goldreturn), data = data)
modelsum <- summary(model)$coef
summary(model)
data$returnestimate <- modelsum["(Intercept)","Estimate"] +
modelsum["index","Estimate"] * data$index +
modelsum["realrate","Estimate"] * data$realrate +
modelsum["lag(goldreturn)","Estimate"] * lag(data$goldreturn)
#Graph Predicted Versus Actual
ggplot(data = data, aes(x = returnestimate, y = goldreturn))+
geom_point()
rm(list = ls())
#Inital Gold Price Model
#Colburn Hassman
#Created 1-29-20
#__NOTES__#
# FRED Codes:
# 30 yr Treasury: DGS30
# 30 Yr Breakeven: T30YIEM
# 20 Yr Treasury: DGS20
# 20 Yr Breakeven: T20YIEM
# 10 Yr Treasury: DGS10
# 10 Yr Breakeven: T10YIE
# 5 Yr Treasury: DGS5
# 5 Yr Breakeven: T5YIE
#Gold: GOLDPMGBD228NLBM
#CPI: CPALTT01USM661S
#Bond estimate from this:
#IDEA SOURCE: https://www.gold.org/goldhub/research/gold-investor/how-i-value-gold
#---Packages---#
library(quantstrat)
library(tidyverse)
library(tidyquant)
library(ggthemes)
library(fredr)
library(ggplot2)
library(TTR)
library(xts)
#Setup#
#setwd("G:My Drive/1_COINS/1_Gold")
fredr_set_key("7dcbffa3096c9b1c9ae4802f6a195f62")
#---USER INPUTS---#
#Observation Start Date
startdate <- as.Date("2004-07-01")
enddate <- as.Date("2019-10-01")
#---Pull Data---#
gold_prices <- data.frame(fredr(series_id = "GOLDPMGBD228NLBM",
observation_start = startdate,
observation_end = enddate,
frequency = "m"))
cpi <- data.frame(fredr(series_id = "CPALTT01USM661S",
observation_start = startdate,
observation_end = enddate,
frequency = "m"))
treas20yr <- data.frame(fredr(series_id = "DGS20",
observation_start = startdate,
observation_end = enddate,
frequency = "m"))
break20yr <- data.frame(fredr(series_id = "T20YIEM",
observation_start = startdate,
observation_end = enddate,
frequency = "m"))
#Model
data <- data.frame("date"=gold_prices$date, "gold"=gold_prices$value, "cpi"=cpi$value, "treas"=treas20yr$value, "breakeven"=break20yr$value,
"goldreturn"=NA, "realrate"=NA, "index"= 1:nrow(gold_prices), "returnestimate"=NA, "bondestimate"=NA,"realrater"=NA, "breakevenr" =NA)
#Remove unneeded data
#rm(gold_prices, cpi, treas20yr, break20yr, enddate, startdate)
#calculate Real Rate of Treasury Return
data$realrate <- data$treas - data$breakeven
plot(ts(data$realrate))
#calculate Gold Return
data$goldreturn <- log(data$gold/lag(data$gold))
plot(ts(data$goldreturn))
abline(h=mean(data$goldreturn,na.rm=TRUE),lty=2)
#Calculate return multipliers for real rate and breakeven
data$realrater <- 1 + (data$realrate / 100)
data$breakevenr <- 1 + (data$breakeven / 100)
#estimate bond fv, as described in website in notes
data$bondestimate <- (data$breakevenr^20)/(data$realrater^20)
#________________________________________________________________________________________#
#Estimate a Model
model <- lm(goldreturn ~ index + realrate, data = data)
modelsum <- summary(model)$coef
# data$returnestimate <- modelsum["(Intercept)","Estimate"] +
#                             modelsum["index","Estimate"] * data$index +
#                             modelsum["realrate","Estimate"] * data$realrate
# Try this instead (Above not entirely correct because you need to drop the first obs in
# each before doing the multiplication:
data$returnestimate <- c(NA,fitted(model))
#Graph Predicted Versus Actual
# Why not plot actual (dots) and predicted (line)
ggplot(data = data, aes(x = returnestimate, y = goldreturn))+ geom_point()
ggplot(data,aes(y=goldreturn,x=date)) +  geom_point()+ stat_smooth(method = "lm",se=FALSE)
#___________________________________________________________________________________________#
#New Model with lag
model <- lm(goldreturn ~ index + realrate + lag(goldreturn), data = data)
modelsum <- summary(model)$coef
summary(model)
data$returnestimate <- modelsum["(Intercept)","Estimate"] +
modelsum["index","Estimate"] * data$index +
modelsum["realrate","Estimate"] * data$realrate +
modelsum["lag(goldreturn)","Estimate"] * lag(data$goldreturn)
#Graph Predicted Versus Actual
ggplot(data = data, aes(x = returnestimate, y = goldreturn))+
geom_point()
#_________________________________________________________________________________________#
#New Model with CPI rather than index
model <- lm(goldreturn ~ cpi + realrate + lag(goldreturn), data = data)
modelsum <- summary(model)$coef
summary(model)
data$returnestimate <- modelsum["(Intercept)","Estimate"] +
modelsum["cpi","Estimate"] * data$index +
modelsum["realrate","Estimate"] * data$realrate +
modelsum["lag(goldreturn)","Estimate"] * lag(data$goldreturn)
#Graph Predicted Versus Actual
ggplot(data = data, aes(x = returnestimate, y = goldreturn))+
geom_point()
#________________________________________________________________________________________#
#New Model with CPI rather than index and bond pricing
model <- lm(goldreturn ~ cpi + realrate + bondestimate + lag(goldreturn), data = data)
modelsum <- summary(model)$coef
summary(model)
data$returnestimate <- modelsum["(Intercept)","Estimate"] +
modelsum["cpi","Estimate"] * data$index +
modelsum["realrate","Estimate"] * data$realrate +
modelsum["lag(goldreturn)","Estimate"] * lag(data$goldreturn) +
modelsum["bondestimate", "Estimate"] * data$bondestimate
#Graph Predicted Versus Actual
library(fpp2)
ggAcf(ts(data$goldreturn))
ggAcf(ts(data$gold))
ggplot(data = data, aes(x = returnestimate, y = goldreturn))+
geom_point()
accuracy(model)
data$date
str(data$date)
xts(gold_prices&value,order.by = gold_prices$date)
xts(gold_prices$value,order.by = gold_prices$date)
ts(gold_prices, start=c(2004,07), frequency = 12)
ts(gold_prices[,2], start=c(2004,07), frequency = 12)
ts(gold_prices$value, start=c(2004,07), frequency = 12)
rm(list = ls())
#Inital Gold Price Model
#Colburn Hassman
#Created 1-29-20
#__NOTES__#
# FRED Codes:
# 30 yr Treasury: DGS30
# 30 Yr Breakeven: T30YIEM
# 20 Yr Treasury: DGS20
# 20 Yr Breakeven: T20YIEM
# 10 Yr Treasury: DGS10
# 10 Yr Breakeven: T10YIE
# 5 Yr Treasury: DGS5
# 5 Yr Breakeven: T5YIE
#Gold: GOLDPMGBD228NLBM
#CPI: CPALTT01USM661S
#Bond estimate from this:
#IDEA SOURCE: https://www.gold.org/goldhub/research/gold-investor/how-i-value-gold
#---Packages---#
library(quantstrat)
library(tidyverse)
library(tidyquant)
library(ggthemes)
library(fredr)
library(ggplot2)
library(TTR)
library(xts)
#Setup#
#setwd("G:My Drive/1_COINS/1_Gold")
fredr_set_key("7dcbffa3096c9b1c9ae4802f6a195f62")
#---USER INPUTS---#
#Observation Start Date
startdate <- as.Date("2004-07-01")
enddate <- as.Date("2019-10-01")
#---Pull Data---#
gold_prices <- data.frame(fredr(series_id = "GOLDPMGBD228NLBM",
observation_start = startdate,
observation_end = enddate,
frequency = "m"))
cpi <- data.frame(fredr(series_id = "CPALTT01USM661S",
observation_start = startdate,
observation_end = enddate,
frequency = "m"))
treas20yr <- data.frame(fredr(series_id = "DGS20",
observation_start = startdate,
observation_end = enddate,
frequency = "m"))
break20yr <- data.frame(fredr(series_id = "T20YIEM",
observation_start = startdate,
observation_end = enddate,
frequency = "m"))
#Model
data <- data.frame("date"=gold_prices$date, "gold"=gold_prices$value, "cpi"=cpi$value, "treas"=treas20yr$value, "breakeven"=break20yr$value,
"goldreturn"=NA, "realrate"=NA, "index"= 1:nrow(gold_prices), "returnestimate"=NA, "bondestimate"=NA,"realrater"=NA, "breakevenr" =NA)
#Remove unneeded data
#rm(gold_prices, cpi, treas20yr, break20yr, enddate, startdate)
#calculate Real Rate of Treasury Return
data$realrate <- data$treas - data$breakeven
plot(ts(data$realrate))
data$goldreturn <- log(data$gold/lag(data$gold))
plot(ts(data$goldreturn))
abline(h=mean(data$goldreturn,na.rm=TRUE),lty=2)
help(chicken)
help(dole)
help("usdeaths")
help(lynx)
autoplot(lynx)
lynx
help(lynx)
help("lynx")
help("goog")
help(writing)
help(fanncy)
help(fancy)
help(a10)
help(h02)
help(bicoal)
help(dole)
help("usdeaths")
tsdisplay(usdeaths)
help(fancy)
seasonplot(fancy)
ggseasonplot(fancy)
autoplot(fancy)
??grid.arrange
help(grid.arrange)
library(fpp2)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = 'H') #Fixes the position of my graphs to where I included them in the document
ggseasonplot(fancy,polar = TRUE)
tsdisplay(dj,plot.type=c("partial", "scatter"))
tsdisplay(dj,plot.type="partial")
tsdisplay(dj,plot.type="scatter")
tsdisplay(dj,plot.type="")
tsdisplay(dj,plot.type=NULL)
autoplot(dj)
help(dj)
autoplot(dj) + ggtitle("Daily Dow-Jones index") + labs(x="",y="")
ggAcf(dj)
data <- read.csv("https://www.eia.gov/totalenergy/data/browser/csv.php?tbl=T01.01")
head(data)
str(data)
data$Column_Order
data$YYYYMM
plot(data$Value)
plot(data$Value,"l")
plot(data$Value,type="l")
View(data)
colnamnes
colnames(data)
subset(data, Column_Order = 12)
subset(data, "Column_Order" = 12)
library(openxlsx)
read.xlsx("https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls")
download.file("https://www.eia.gov/totalenergy/data/browser/csv.php?tbl=T01.01", destfile = tmp, mode="wb")
download.file("https://www.eia.gov/totalenergy/data/browser/csv.php?tbl=T01.01", mode="wb")
data <- download.file(url = "https://www.eia.gov/totalenergy/data/browser/csv.php?tbl=T01.01", destfile = tmp, mode="wb")
data <- download.file(url = "https://www.eia.gov/totalenergy/data/browser/csv.php?tbl=T01.01", destfile = tmp)
data <- download.file(url = "https://www.eia.gov/totalenergy/data/browser/csv.php?tbl=T01.01", destfile = tempfile(fileext = ".xlsx"), mode="wb")
data
download.file(url = "http://www.eia.gov/petroleum/drilling/xls/dpr-data.xlsx", destfile = tmp, mode="wb")
tmp = tempfile(fileext = ".xlsx")
download.file(url = "http://www.eia.gov/petroleum/drilling/xls/dpr-data.xlsx", destfile = tmp, mode="wb")
tmp
data <- download.file(url = "https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls",
destfile = temp, mode="wb")
data <- download.file(url = "https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls",
destfile = tmp, mode="wb")
data
plot(tmp)
ls()
read.xlsx(tmp)
tmp
read_xlsx(tmp)
read.xlsx(tmp, sheet = 1)
read.xlsx(tmp, sheet = 2)
install.packages("XLConnect")
library(XLConnect)
install.packages("XLConnect", dependencies = TRUE)
library(XLConnect)
data <- download.file(url = "https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls",
destfile = tmp, mode="wb")
tmp <- tempfile(fileext = ".xlsx")
data <- download.file(url = "https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls",
destfile = tmp, mode="wb")
read.xlsx(tmp, sheet = 1)
read.xlsx(tmp)
library(openxlsx)
tmp <- tempfile(fileext = ".xlsx")
data <- download.file(url = "https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls",
destfile = tmp, mode="wb")
tmp
read.xlsx("https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls")
read.xls("https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls")
tmp <- tempfile(fileext = ".xls")
data <- download.file(url = "https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls",
destfile = tmp, mode="wb")
open.xlsx(tmp)
read.xlsx(tmp)
loadWorkbook(tmp)
readWorkbook(tmp)
install.packages("gdata")
library(gdata)
gdata::read.xls(tmp)
install.packages("readxl")
readxl::read_excel(tmp)
readxl::read_excel(tmp,sheet = 2)
readxl::read_excel(tmp,sheet = 2,skip = 2)
conng <- readxl::read_excel(tmp,sheet = 2,skip = 2)
time(conng)
ts(conng,start=c(1973,1), frequency = 12)
ts(conng[,-1],start=c(1973,1), frequency = 12)
ngdata <- readxl::read_excel(tmp,sheet = 2,skip = 2)
tsng <- ts(ngdata[,-1],start=c(1973,1), frequency = 12)
tsng[,1]
conng <- window(tsng[,1],start=c(2001,1))
conng
autoplot(conng)
library(fpp2)
autoplot(conng)
autoplot(conng/1000)
head(conng/1000)
ggsubseriesplot(conng)
ggseasonplot(conng)
ggseasonplot(conng,polar=TRUE)
ggseasonplot(conng,year.labels = TRUE)
ggAcf(conng)
ggAcf(conng,lag.max = 36)
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
g1 <- ggsubseriesplot(conng)
g2 <- ggseasonplot(conng,year.labels = TRUE)
g3 <- ggAcf(conng,lag.max = 36)
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
# Need to install the readxl package
install.packages("readxl")
library(fpp2)
# Explain the steps here
tmp <- tempfile(fileext = ".xls") # Storing the file to your computer's temporary memory
#pulling down the data from EIA
data <- download.file(url = "https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls",
destfile = tmp, mode="wb")
#USe the readxl command to read the temporary file into R. Be sure to skip the first 2 rows.
ngdata <- readxl::read_excel(tmp,sheet = 2,skip = 2)
# Drop the original date column and convert ngdata to a time series object starting at January 1973.
# Be sure to specify the proper frequency
tsng <- ts(ngdata[,-1],start=c(1973,1), frequency = 12)
# Now use the window command to drop all observations before January 2001. Save this as conng
conng <- window(tsng[,1],start=c(2001,1))
#convert conng to BCFs (it's ok to save back into conng)
conng <- conng/1000
# Present a time plot of conng. Remember to properly label your axes.
autoplot(conng)
# As we usually do, use the tools you have learnt so far to comment on possible seasonality and
# trends in the consumption data.
g1 <- ggsubseriesplot(conng)
g2 <- ggseasonplot(conng,year.labels = TRUE)
g3 <- ggAcf(conng,lag.max = 36)
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
install.packages("readxl")
g3 <- ggAcf(conng,lag.max = 36,col=blues9)
g1 <- ggsubseriesplot(conng)
g2 <- ggseasonplot(conng,year.labels = TRUE)
g3 <- ggAcf(conng,lag.max = 36,col=blues9)
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
library(fpp2)
g1 <- ggsubseriesplot(conng)
g2 <- ggseasonplot(conng,year.labels = TRUE)
g3 <- ggAcf(conng,lag.max = 36,col=blues9)
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
g3 <- ggAcf(conng,lag.max = 36,col="blue9")
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
g3 <- ggAcf(conng,lag.max = 36,col="blue")
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
g1 <- ggsubseriesplot(conng,col=rainbow)
g2 <- ggseasonplot(conng,year.labels = TRUE)
g3 <- ggAcf(conng,lag.max = 36,col="blue")
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
g2 <- ggseasonplot(conng,year.labels = TRUE,rainbow(9))
g2 <- ggseasonplot(conng,year.labels = TRUE,rainbow(12))
g3 <- ggAcf(conng,lag.max = 36,col="blue")
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
g2 <- ggseasonplot(conng,year.labels = TRUE,col=rainbow(12))
g3 <- ggAcf(conng,lag.max = 36,col="blue")
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
g2 <- ggseasonplot(conng,year.labels = TRUE,c(J,N))
g2 <- ggseasonplot(conng,year.labels = TRUE,c("J,N"))
g2 <- ggseasonplot(conng,year.labels = TRUE,c(rep("J,N",12)))
g3 <- ggAcf(conng,lag.max = 36,col="blue")
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
g1 <- ggsubseriesplot(conng)
g2 <- ggseasonplot(conng,year.labels = TRUE)
g3 <- ggAcf(conng,lag.max = 36,col="blue")
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
colnames(ngdata)
library(fpp2)
library(ggplot2)
#install.packages("readxl") # Need to install the readxl package
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = 'H') #Fixes the position of my graphs to where I included them in the document
autoplot(conng) + ggtitle("Total Natural Gas Consumption by End Use") + labs(y="Bcf",x="")
time(conng)
rwf(train.conng,drift = TRUE)
library(fpp2)
library(ggplot2)
#install.packages("readxl") # Need to install the readxl package
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.pos = 'H') #Fixes the position of my graphs to where I included them in the document
tmp <- tempfile(fileext = ".xls") # Storing the file to your computer's temporary memory
#Pull data from EIA
download.file(url = "https://www.eia.gov/dnav/ng/xls/NG_CONS_SUM_DCU_NUS_M.xls",destfile = tmp,
mode="wb")
ngdata <- readxl::read_excel(tmp, sheet = 2, skip = 2)
tsng <- ts(ngdata[,-1],start=c(1973,1), frequency = 12)
conng <- window(tsng[,1],start=c(2001,1))
conng <- conng/1000
autoplot(conng) + ggtitle("Total US Natural Gas Consumption") + labs(y="Bcf",x="")
g1 <- ggsubseriesplot(conng) + ggtitle("Subseries: US NG Consumption") + ylab ("Bcf")
g2 <- ggseasonplot(conng,year.labels = TRUE) + ggtitle("Seasonal plot: US NG Consumption")
g3 <- ggAcf(conng,lag.max = 36,col="blue") + ggtitle("ACF: US NG Consumption")
gridExtra::grid.arrange(g1,g2,g3, nrow=3,newpage = TRUE)
train.conng <- window(conng,end = c(2015,12))
test.conng <- window(conng, start = c(2016,1))
autoplot(conng) +
autolayer(train.conng, series="Training") +
autolayer(test.conng, series="Test")
fc1 <- meanf(train.conng)
fc2 <- naive(train.conng)
fc3 <- snaive(train.conng)
fc4 <- rwf(train.conng,drift = TRUE)
fc4
naive(train.conng==rwf(train.conng)
)
naive(train.conng)==rwf(train.conng
naive(train.conng)==rwf(train.conng)
naive(train.conng)
rwf(train.conng)
autoplot(conng) + autolayer(fc1)
autoplot(conng) + autolayer(fc1,PI = FALSE)
autoplot(train.conng) + autolayer(fc1,PI = FALSE) + autolayer(fc2,PI = FALSE) + autolayer(fc3,PI = FALSE) + autolayer(fc4,PI = FALSE)
autoplot(train.conng) + autolayer(fc1,PI = FALSE, series = "Mean") + autolayer(fc2,PI = FALSE, series = "Naïve") + autolayer(fc3,PI = FALSE, series = "Seasonal Naïve") + autolayer(fc4,PI = FALSE,series = "Drift")
autoplot(train.conng) + autolayer(fc1,PI = FALSE, series = "Mean") + autolayer(fc2,PI = FALSE, series = "Naïve") + autolayer(fc3,PI = FALSE, series = "Seasonal Naïve") + autolayer(fc4,PI = FALSE,series = "Drift")
autoplot(train.conng) + autolayer(fc1,PI = FALSE, series = "Mean") + autolayer(fc2,PI = FALSE, series = "Naïve") + autolayer(fc3,PI = FALSE, series = "Seasonal Naïve")
accuracy(fc1,test.conng)
accuracy(fc2,test.conng)
accuracy(fc3,test.conng)
accuracy(fc1,test.conng)[,c("RMSE","MAE","MAPE")]
round(accuracy(fc1,test.conng)[,c("RMSE","MAE","MAPE")],3)
round(accuracy(fc1,test.conng)[,c("RMSE","MAE","MAPE")],3)
round(accuracy(fc2,test.conng)[,c("RMSE","MAE","MAPE")],3)
round(accuracy(fc3,test.conng)[,c("RMSE","MAE","MAPE")],3)
round(accuracy(fc1,test.conng)["Test set",c("RMSE","MAE","MAPE","Theil's U")],3)
round(accuracy(fc1,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
round(accuracy(fc2,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
round(accuracy(fc3,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
rbind(r1,r2,r3)
r1 <- round(accuracy(fc1,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
r2 <- round(accuracy(fc2,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
r3 <- round(accuracy(fc3,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
rbind(r1,r2,r3)
r1 <- round(accuracy(fc1,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
r2 <- round(accuracy(fc2,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
r3 <- round(accuracy(fc3,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
accuracy.tab <- as.table(rbind(r1,r2,r3))
row.names(accuracy.tab) <- c("Mean","Naïve","Seasonal Naïve")
print(accuracy.tab)
as.table(rbind("Mean" = r1, "Mean" = r2, "Mean" = r3))
r1 <- round(accuracy(fc1,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
r2 <- round(accuracy(fc2,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
r3 <- round(accuracy(fc3,test.conng)[2,c("RMSE","MAE","MAPE","Theil's U")],3)
accuracy.tab <- as.table(rbind("Mean" = r1, "Naïve"= r2, "Seasonal Naïve" = r3))
accuracy.tab
checkresiduals(fc1)
accuracy.tab
r1 <- round(accuracy(fc1,test.conng)[2,c("RMSE","MAE","MAPE","MASE","Theil's U")],3)
r2 <- round(accuracy(fc2,test.conng)[2,c("RMSE","MAE","MAPE","MASE","Theil's U")],3)
r3 <- round(accuracy(fc3,test.conng)[2,c("RMSE","MAE","MAPE","MASE","Theil's U")],3)
accuracy.tab <- as.table(rbind("Mean" = r1, "Naïve"= r2, "Seasonal Naïve" = r3))
accuracy.tab
r1 <- round(accuracy(fc1,test.conng)[2,c("RMSE","MAE","MAPE","MASE")],3)
r2 <- round(accuracy(fc2,test.conng)[2,c("RMSE","MAE","MAPE","MASE")],3)
r3 <- round(accuracy(fc3,test.conng)[2,c("RMSE","MAE","MAPE","MASE")],3)
accuracy.tab <- as.table(rbind("Mean" = r1, "Naïve"= r2, "Seasonal Naïve" = r3))
accuracy.tab
str(checkresiduals(fc1, plot = FALSE))
(checkresiduals(fc1, plot = FALSE))$statistics
(checkresiduals(fc1, plot = FALSE))$statistic
statistic(checkresiduals(fc1, plot = FALSE))
checkresiduals(fc1, plot = FALSE)$p.value
setwd("C:/Users/stewartls/Dropbox/Teaching/AppliedForecasting/Spring 2020/Homework/Homework2")
